// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Text.Json;
using System.Threading;
using System.Threading.Tasks;
using Azure;
using Azure.Core;
using Azure.Core.Pipeline;
using Microsoft.PowerBI.Api.Models;

namespace Microsoft.PowerBI.Api
{
    internal partial class ImportsRestClient
    {
        private readonly HttpPipeline _pipeline;
        private readonly Uri _endpoint;

        /// <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        internal ClientDiagnostics ClientDiagnostics { get; }

        /// <summary> Initializes a new instance of ImportsRestClient. </summary>
        /// <param name="clientDiagnostics"> The handler for diagnostic messaging in the client. </param>
        /// <param name="pipeline"> The HTTP pipeline for sending and receiving REST requests and responses. </param>
        /// <param name="endpoint"> server parameter. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="clientDiagnostics"/> or <paramref name="pipeline"/> is null. </exception>
        public ImportsRestClient(ClientDiagnostics clientDiagnostics, HttpPipeline pipeline, Uri endpoint = null)
        {
            ClientDiagnostics = clientDiagnostics ?? throw new ArgumentNullException(nameof(clientDiagnostics));
            _pipeline = pipeline ?? throw new ArgumentNullException(nameof(pipeline));
            _endpoint = endpoint ?? new Uri("https://api.powerbi.com");
        }

        internal HttpMessage CreateGetImportsRequest()
        {
            var message = _pipeline.CreateMessage();
            var request = message.Request;
            request.Method = RequestMethod.Get;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/v1.0/myorg/imports", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            return message;
        }

        /// <summary> Returns a list of imports from **My workspace**. </summary>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All or Dataset.Read.All
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public async Task<Response<Imports>> GetImportsAsync(CancellationToken cancellationToken = default)
        {
            using var message = CreateGetImportsRequest();
            await _pipeline.SendAsync(message, cancellationToken).ConfigureAwait(false);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        Imports value = default;
                        using var document = await JsonDocument.ParseAsync(message.Response.ContentStream, default, cancellationToken).ConfigureAwait(false);
                        value = Imports.DeserializeImports(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        /// <summary> Returns a list of imports from **My workspace**. </summary>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All or Dataset.Read.All
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public Response<Imports> GetImports(CancellationToken cancellationToken = default)
        {
            using var message = CreateGetImportsRequest();
            _pipeline.Send(message, cancellationToken);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        Imports value = default;
                        using var document = JsonDocument.Parse(message.Response.ContentStream);
                        value = Imports.DeserializeImports(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        internal HttpMessage CreatePostImportRequest(string datasetDisplayName, ImportInfo importInfo, ImportConflictHandlerMode? nameConflict, bool? skipReport, bool? overrideReportLabel, bool? overrideModelLabel, Guid? subfolderObjectId)
        {
            var message = _pipeline.CreateMessage();
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/v1.0/myorg/imports", false);
            uri.AppendQuery("datasetDisplayName", datasetDisplayName, true);
            if (nameConflict != null)
            {
                uri.AppendQuery("nameConflict", nameConflict.Value.ToSerialString(), true);
            }
            if (skipReport != null)
            {
                uri.AppendQuery("skipReport", skipReport.Value, true);
            }
            if (overrideReportLabel != null)
            {
                uri.AppendQuery("overrideReportLabel", overrideReportLabel.Value, true);
            }
            if (overrideModelLabel != null)
            {
                uri.AppendQuery("overrideModelLabel", overrideModelLabel.Value, true);
            }
            if (subfolderObjectId != null)
            {
                uri.AppendQuery("subfolderObjectId", subfolderObjectId.Value, true);
            }
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            var content = new Utf8JsonRequestContent();
            content.JsonWriter.WriteObjectValue(importInfo);
            request.Content = content;
            return message;
        }

        /// <summary> Creates new content in **My workspace**. </summary>
        /// <param name="datasetDisplayName"> The display name of the dataset, should include file extension. Not supported when importing from OneDrive for Business. </param>
        /// <param name="importInfo"> The import to post. </param>
        /// <param name="nameConflict"> Specifies what to do if a dataset with the same name already exists. The default value is `Ignore`. For RDL files, `Abort` and `Overwrite` are the only supported options. </param>
        /// <param name="skipReport"> Whether to skip report import. If specified, the value must be `true`. Only supported for Power BI .pbix files. </param>
        /// <param name="overrideReportLabel"> Whether to override the existing report label when republishing a Power BI .pbix file. The service default value is `true`. </param>
        /// <param name="overrideModelLabel"> Whether to override the existing label on a model when republishing a Power BI .pbix file. The service default value is `true`. </param>
        /// <param name="subfolderObjectId"> The subfolder ID to import the file to subfolder. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="datasetDisplayName"/> or <paramref name="importInfo"/> is null. </exception>
        /// <remarks>
        /// See the [Import Large Files](https://github.com/microsoft/PowerBI-Developer-Samples/blob/master/PowerShell%20Scripts/Import%20Large%20Files) PowerShell script for an example of using this API.
        ///
        /// &gt; [!NOTE]
        /// &gt; Supported content:
        /// &gt; - Power BI .pbix files
        /// &gt; - JSON files (.json)
        /// &gt; - Excel files (.xlsx)
        /// &gt; - RDL files (.rdl)
        ///
        /// - To import a file, specify the content type **multipart/form-data** in the request headers and encode the file as [form data](https://www.w3.org/TR/html401/interact/forms.html) in the request body.
        /// - To import an .rdl file, include the file extension in the name specified by `datasetDisplayName`, as described in [URI parameters](/rest/api/power-bi/imports/post-import-in-group#uri-parameters).
        /// - To import an .xlsx file from OneDrive for Business, include the content type **application/json** in the request headers. Include [ImportInfo](/rest/api/power-bi/imports/post-import-in-group#importinfo) with `filePath` set to the .xlsx file path in the request body.
        /// - To import large Power BI .pbix files that are between 1 GB and 10 GB in size, see [Create Temporary Upload Location](/rest/api/power-bi/imports/create-temporary-upload-location). This is only supported for Premium capacity workspaces.
        /// - To create a dataflow from a model.json file, set `datasetDisplayName` to *model.json*, as described in [URI parameters](/rest/api/power-bi/imports/post-import-in-group#uri-parameters).
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All
        ///
        /// ## Limitations
        ///
        /// - Dataflows with service principal aren't supported.
        /// - Importing a Power BI .pbix file from OneDrive isn't supported.
        /// - Importing a file that has a **protected** sensitivity label isn't supported for service principals.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public async Task<Response<Import>> PostImportAsync(string datasetDisplayName, ImportInfo importInfo, ImportConflictHandlerMode? nameConflict = null, bool? skipReport = null, bool? overrideReportLabel = null, bool? overrideModelLabel = null, Guid? subfolderObjectId = null, CancellationToken cancellationToken = default)
        {
            if (datasetDisplayName == null)
            {
                throw new ArgumentNullException(nameof(datasetDisplayName));
            }
            if (importInfo == null)
            {
                throw new ArgumentNullException(nameof(importInfo));
            }

            using var message = CreatePostImportRequest(datasetDisplayName, importInfo, nameConflict, skipReport, overrideReportLabel, overrideModelLabel, subfolderObjectId);
            await _pipeline.SendAsync(message, cancellationToken).ConfigureAwait(false);
            switch (message.Response.Status)
            {
                case 200:
                case 202:
                    {
                        Import value = default;
                        using var document = await JsonDocument.ParseAsync(message.Response.ContentStream, default, cancellationToken).ConfigureAwait(false);
                        value = Import.DeserializeImport(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        /// <summary> Creates new content in **My workspace**. </summary>
        /// <param name="datasetDisplayName"> The display name of the dataset, should include file extension. Not supported when importing from OneDrive for Business. </param>
        /// <param name="importInfo"> The import to post. </param>
        /// <param name="nameConflict"> Specifies what to do if a dataset with the same name already exists. The default value is `Ignore`. For RDL files, `Abort` and `Overwrite` are the only supported options. </param>
        /// <param name="skipReport"> Whether to skip report import. If specified, the value must be `true`. Only supported for Power BI .pbix files. </param>
        /// <param name="overrideReportLabel"> Whether to override the existing report label when republishing a Power BI .pbix file. The service default value is `true`. </param>
        /// <param name="overrideModelLabel"> Whether to override the existing label on a model when republishing a Power BI .pbix file. The service default value is `true`. </param>
        /// <param name="subfolderObjectId"> The subfolder ID to import the file to subfolder. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="datasetDisplayName"/> or <paramref name="importInfo"/> is null. </exception>
        /// <remarks>
        /// See the [Import Large Files](https://github.com/microsoft/PowerBI-Developer-Samples/blob/master/PowerShell%20Scripts/Import%20Large%20Files) PowerShell script for an example of using this API.
        ///
        /// &gt; [!NOTE]
        /// &gt; Supported content:
        /// &gt; - Power BI .pbix files
        /// &gt; - JSON files (.json)
        /// &gt; - Excel files (.xlsx)
        /// &gt; - RDL files (.rdl)
        ///
        /// - To import a file, specify the content type **multipart/form-data** in the request headers and encode the file as [form data](https://www.w3.org/TR/html401/interact/forms.html) in the request body.
        /// - To import an .rdl file, include the file extension in the name specified by `datasetDisplayName`, as described in [URI parameters](/rest/api/power-bi/imports/post-import-in-group#uri-parameters).
        /// - To import an .xlsx file from OneDrive for Business, include the content type **application/json** in the request headers. Include [ImportInfo](/rest/api/power-bi/imports/post-import-in-group#importinfo) with `filePath` set to the .xlsx file path in the request body.
        /// - To import large Power BI .pbix files that are between 1 GB and 10 GB in size, see [Create Temporary Upload Location](/rest/api/power-bi/imports/create-temporary-upload-location). This is only supported for Premium capacity workspaces.
        /// - To create a dataflow from a model.json file, set `datasetDisplayName` to *model.json*, as described in [URI parameters](/rest/api/power-bi/imports/post-import-in-group#uri-parameters).
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All
        ///
        /// ## Limitations
        ///
        /// - Dataflows with service principal aren't supported.
        /// - Importing a Power BI .pbix file from OneDrive isn't supported.
        /// - Importing a file that has a **protected** sensitivity label isn't supported for service principals.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public Response<Import> PostImport(string datasetDisplayName, ImportInfo importInfo, ImportConflictHandlerMode? nameConflict = null, bool? skipReport = null, bool? overrideReportLabel = null, bool? overrideModelLabel = null, Guid? subfolderObjectId = null, CancellationToken cancellationToken = default)
        {
            if (datasetDisplayName == null)
            {
                throw new ArgumentNullException(nameof(datasetDisplayName));
            }
            if (importInfo == null)
            {
                throw new ArgumentNullException(nameof(importInfo));
            }

            using var message = CreatePostImportRequest(datasetDisplayName, importInfo, nameConflict, skipReport, overrideReportLabel, overrideModelLabel, subfolderObjectId);
            _pipeline.Send(message, cancellationToken);
            switch (message.Response.Status)
            {
                case 200:
                case 202:
                    {
                        Import value = default;
                        using var document = JsonDocument.Parse(message.Response.ContentStream);
                        value = Import.DeserializeImport(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        internal HttpMessage CreateGetImportRequest(Guid importId)
        {
            var message = _pipeline.CreateMessage();
            var request = message.Request;
            request.Method = RequestMethod.Get;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/v1.0/myorg/imports/", false);
            uri.AppendPath(importId, true);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            return message;
        }

        /// <summary> Returns the specified import from **My workspace**. </summary>
        /// <param name="importId"> The import ID. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All or Dataset.Read.All
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public async Task<Response<Import>> GetImportAsync(Guid importId, CancellationToken cancellationToken = default)
        {
            using var message = CreateGetImportRequest(importId);
            await _pipeline.SendAsync(message, cancellationToken).ConfigureAwait(false);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        Import value = default;
                        using var document = await JsonDocument.ParseAsync(message.Response.ContentStream, default, cancellationToken).ConfigureAwait(false);
                        value = Import.DeserializeImport(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        /// <summary> Returns the specified import from **My workspace**. </summary>
        /// <param name="importId"> The import ID. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All or Dataset.Read.All
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public Response<Import> GetImport(Guid importId, CancellationToken cancellationToken = default)
        {
            using var message = CreateGetImportRequest(importId);
            _pipeline.Send(message, cancellationToken);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        Import value = default;
                        using var document = JsonDocument.Parse(message.Response.ContentStream);
                        value = Import.DeserializeImport(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        internal HttpMessage CreateCreateTemporaryUploadLocationRequest()
        {
            var message = _pipeline.CreateMessage();
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/v1.0/myorg/imports/createTemporaryUploadLocation", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            return message;
        }

        /// <summary> Creates a temporary blob storage upload location for importing large Power BI .pbix files that are between 1 GB and 10 GB in size. </summary>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// To import large Power BI .pbix files:
        ///
        /// 1. Create a temporary upload location using this API call.
        /// 1. Upload the Power BI .pbix files using the *shared access signature* URL from the API call response.
        /// 1. Call [Post Import In Group](/rest/api/power-bi/imports/post-import), specifying the *shared access signature* URL in the `fileUrl` parameter of the [request body](/rest/api/power-bi/imports/post-import#request-body).
        ///
        /// See the [Import Large Files](https://github.com/microsoft/PowerBI-Developer-Samples/blob/master/PowerShell%20Scripts/Import%20Large%20Files) PowerShell script for an example of using this API.
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All
        ///
        /// ## Limitations
        ///
        /// Importing large Power BI .pbix files between 1 GB and 10 GB in size is only available for Premium capacity workspaces.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public async Task<Response<TemporaryUploadLocation>> CreateTemporaryUploadLocationAsync(CancellationToken cancellationToken = default)
        {
            using var message = CreateCreateTemporaryUploadLocationRequest();
            await _pipeline.SendAsync(message, cancellationToken).ConfigureAwait(false);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        TemporaryUploadLocation value = default;
                        using var document = await JsonDocument.ParseAsync(message.Response.ContentStream, default, cancellationToken).ConfigureAwait(false);
                        value = TemporaryUploadLocation.DeserializeTemporaryUploadLocation(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        /// <summary> Creates a temporary blob storage upload location for importing large Power BI .pbix files that are between 1 GB and 10 GB in size. </summary>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// To import large Power BI .pbix files:
        ///
        /// 1. Create a temporary upload location using this API call.
        /// 1. Upload the Power BI .pbix files using the *shared access signature* URL from the API call response.
        /// 1. Call [Post Import In Group](/rest/api/power-bi/imports/post-import), specifying the *shared access signature* URL in the `fileUrl` parameter of the [request body](/rest/api/power-bi/imports/post-import#request-body).
        ///
        /// See the [Import Large Files](https://github.com/microsoft/PowerBI-Developer-Samples/blob/master/PowerShell%20Scripts/Import%20Large%20Files) PowerShell script for an example of using this API.
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All
        ///
        /// ## Limitations
        ///
        /// Importing large Power BI .pbix files between 1 GB and 10 GB in size is only available for Premium capacity workspaces.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public Response<TemporaryUploadLocation> CreateTemporaryUploadLocation(CancellationToken cancellationToken = default)
        {
            using var message = CreateCreateTemporaryUploadLocationRequest();
            _pipeline.Send(message, cancellationToken);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        TemporaryUploadLocation value = default;
                        using var document = JsonDocument.Parse(message.Response.ContentStream);
                        value = TemporaryUploadLocation.DeserializeTemporaryUploadLocation(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        internal HttpMessage CreateGetImportsInGroupRequest(Guid groupId)
        {
            var message = _pipeline.CreateMessage();
            var request = message.Request;
            request.Method = RequestMethod.Get;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/v1.0/myorg/groups/", false);
            uri.AppendPath(groupId, true);
            uri.AppendPath("/imports", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            return message;
        }

        /// <summary> Returns a list of imports from the specified workspace. </summary>
        /// <param name="groupId"> The workspace ID. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// ## Permissions
        ///
        /// This API call can be called by a service principal profile. For more information see: [Service principal profiles in Power BI Embedded](/power-bi/developer/embedded/embed-multi-tenancy).
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All or Dataset.Read.All
        ///
        /// ## Limitations
        ///
        /// Importing Power BI .pbix files from OneDrive isn't supported.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public async Task<Response<Imports>> GetImportsInGroupAsync(Guid groupId, CancellationToken cancellationToken = default)
        {
            using var message = CreateGetImportsInGroupRequest(groupId);
            await _pipeline.SendAsync(message, cancellationToken).ConfigureAwait(false);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        Imports value = default;
                        using var document = await JsonDocument.ParseAsync(message.Response.ContentStream, default, cancellationToken).ConfigureAwait(false);
                        value = Imports.DeserializeImports(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        /// <summary> Returns a list of imports from the specified workspace. </summary>
        /// <param name="groupId"> The workspace ID. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// ## Permissions
        ///
        /// This API call can be called by a service principal profile. For more information see: [Service principal profiles in Power BI Embedded](/power-bi/developer/embedded/embed-multi-tenancy).
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All or Dataset.Read.All
        ///
        /// ## Limitations
        ///
        /// Importing Power BI .pbix files from OneDrive isn't supported.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public Response<Imports> GetImportsInGroup(Guid groupId, CancellationToken cancellationToken = default)
        {
            using var message = CreateGetImportsInGroupRequest(groupId);
            _pipeline.Send(message, cancellationToken);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        Imports value = default;
                        using var document = JsonDocument.Parse(message.Response.ContentStream);
                        value = Imports.DeserializeImports(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        internal HttpMessage CreatePostImportInGroupRequest(Guid groupId, string datasetDisplayName, ImportInfo importInfo, ImportConflictHandlerMode? nameConflict, bool? skipReport, bool? overrideReportLabel, bool? overrideModelLabel, Guid? subfolderObjectId)
        {
            var message = _pipeline.CreateMessage();
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/v1.0/myorg/groups/", false);
            uri.AppendPath(groupId, true);
            uri.AppendPath("/imports", false);
            uri.AppendQuery("datasetDisplayName", datasetDisplayName, true);
            if (nameConflict != null)
            {
                uri.AppendQuery("nameConflict", nameConflict.Value.ToSerialString(), true);
            }
            if (skipReport != null)
            {
                uri.AppendQuery("skipReport", skipReport.Value, true);
            }
            if (overrideReportLabel != null)
            {
                uri.AppendQuery("overrideReportLabel", overrideReportLabel.Value, true);
            }
            if (overrideModelLabel != null)
            {
                uri.AppendQuery("overrideModelLabel", overrideModelLabel.Value, true);
            }
            if (subfolderObjectId != null)
            {
                uri.AppendQuery("subfolderObjectId", subfolderObjectId.Value, true);
            }
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            var content = new Utf8JsonRequestContent();
            content.JsonWriter.WriteObjectValue(importInfo);
            request.Content = content;
            return message;
        }

        /// <summary> Creates new content in the specified workspace. </summary>
        /// <param name="groupId"> The workspace ID. </param>
        /// <param name="datasetDisplayName"> The display name of the dataset should include file extension. Not supported when importing from OneDrive for Business. For importing or creating dataflows, this parameter should be hardcoded to model.json. </param>
        /// <param name="importInfo"> The import to post. </param>
        /// <param name="nameConflict"> Specifies what to do if a dataset with the same name already exists. The default value is `Ignore`. For RDL files, `Abort` and `Overwrite` are the only supported options. For dataflow model.json files, `Abort` and `GenerateUniqueName` are the only supported options. </param>
        /// <param name="skipReport"> Whether to skip report import. If specified, the value must be `true`. Only supported for Power BI .pbix files. </param>
        /// <param name="overrideReportLabel"> Whether to override the existing label on a report when republishing a Power BI .pbix file. The service default value is `true`. </param>
        /// <param name="overrideModelLabel"> Determines whether to override the existing label on a model when republishing a Power BI .pbix file. The service default value is `true`. </param>
        /// <param name="subfolderObjectId"> The subfolder ID to import the file to subfolder. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="datasetDisplayName"/> or <paramref name="importInfo"/> is null. </exception>
        /// <remarks>
        /// &gt; [!NOTE]
        /// &gt; Supported content:
        /// &gt;
        /// &gt; - Power BI .pbix files
        /// &gt; - JSON files (.json)
        /// &gt; - Excel files (.xlsx)
        /// &gt; - SQL Server Report Definition Language files (.rdl)
        ///
        /// - To import a file, specify the content type **multipart/form-data** in the request headers and encode the file as [form data](https://www.w3.org/TR/html401/interact/forms.html) in the request body.
        /// - To import an .rdl file, include the file extension in the name specified by `datasetDisplayName`, as described in [URI parameters](/rest/api/power-bi/imports/post-import-in-group#uri-parameters).
        /// - To import an .xlsx file from OneDrive for Business, include the content type **application/json** in the request headers. Include [ImportInfo](/rest/api/power-bi/imports/post-import-in-group#importinfo) with `filePath` set to the .xlsx file path in the request body.
        /// - To import large Power BI .pbix files that are between 1 GB and 10 GB in size, see [Create Temporary Upload Location In Group](/rest/api/power-bi/imports/create-temporary-upload-location-in-group) and the [Import Large Files](https://github.com/microsoft/PowerBI-Developer-Samples/blob/master/PowerShell%20Scripts/Import%20Large%20Files) PowerShell script. This is only supported for Premium capacity workspaces.
        /// - To create a dataflow from a model.json file, set `datasetDisplayName` to *model.json*, as described in [URI parameters](/rest/api/power-bi/imports/post-import-in-group#uri-parameters).
        ///
        /// ## Permissions
        ///
        /// This API call can be called by a service principal profile. For more information see: [Service principal profiles in Power BI Embedded](/power-bi/developer/embedded/embed-multi-tenancy).
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All
        ///
        /// ## Limitations
        ///
        /// - Dataflows with service principal aren't supported.
        /// - Importing a Power BI .pbix file from OneDrive isn't supported.
        /// - Importing a file that has a **protected** sensitivity label isn't supported for service principals.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public async Task<Response<Import>> PostImportInGroupAsync(Guid groupId, string datasetDisplayName, ImportInfo importInfo, ImportConflictHandlerMode? nameConflict = null, bool? skipReport = null, bool? overrideReportLabel = null, bool? overrideModelLabel = null, Guid? subfolderObjectId = null, CancellationToken cancellationToken = default)
        {
            if (datasetDisplayName == null)
            {
                throw new ArgumentNullException(nameof(datasetDisplayName));
            }
            if (importInfo == null)
            {
                throw new ArgumentNullException(nameof(importInfo));
            }

            using var message = CreatePostImportInGroupRequest(groupId, datasetDisplayName, importInfo, nameConflict, skipReport, overrideReportLabel, overrideModelLabel, subfolderObjectId);
            await _pipeline.SendAsync(message, cancellationToken).ConfigureAwait(false);
            switch (message.Response.Status)
            {
                case 200:
                case 202:
                    {
                        Import value = default;
                        using var document = await JsonDocument.ParseAsync(message.Response.ContentStream, default, cancellationToken).ConfigureAwait(false);
                        value = Import.DeserializeImport(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        /// <summary> Creates new content in the specified workspace. </summary>
        /// <param name="groupId"> The workspace ID. </param>
        /// <param name="datasetDisplayName"> The display name of the dataset should include file extension. Not supported when importing from OneDrive for Business. For importing or creating dataflows, this parameter should be hardcoded to model.json. </param>
        /// <param name="importInfo"> The import to post. </param>
        /// <param name="nameConflict"> Specifies what to do if a dataset with the same name already exists. The default value is `Ignore`. For RDL files, `Abort` and `Overwrite` are the only supported options. For dataflow model.json files, `Abort` and `GenerateUniqueName` are the only supported options. </param>
        /// <param name="skipReport"> Whether to skip report import. If specified, the value must be `true`. Only supported for Power BI .pbix files. </param>
        /// <param name="overrideReportLabel"> Whether to override the existing label on a report when republishing a Power BI .pbix file. The service default value is `true`. </param>
        /// <param name="overrideModelLabel"> Determines whether to override the existing label on a model when republishing a Power BI .pbix file. The service default value is `true`. </param>
        /// <param name="subfolderObjectId"> The subfolder ID to import the file to subfolder. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="datasetDisplayName"/> or <paramref name="importInfo"/> is null. </exception>
        /// <remarks>
        /// &gt; [!NOTE]
        /// &gt; Supported content:
        /// &gt;
        /// &gt; - Power BI .pbix files
        /// &gt; - JSON files (.json)
        /// &gt; - Excel files (.xlsx)
        /// &gt; - SQL Server Report Definition Language files (.rdl)
        ///
        /// - To import a file, specify the content type **multipart/form-data** in the request headers and encode the file as [form data](https://www.w3.org/TR/html401/interact/forms.html) in the request body.
        /// - To import an .rdl file, include the file extension in the name specified by `datasetDisplayName`, as described in [URI parameters](/rest/api/power-bi/imports/post-import-in-group#uri-parameters).
        /// - To import an .xlsx file from OneDrive for Business, include the content type **application/json** in the request headers. Include [ImportInfo](/rest/api/power-bi/imports/post-import-in-group#importinfo) with `filePath` set to the .xlsx file path in the request body.
        /// - To import large Power BI .pbix files that are between 1 GB and 10 GB in size, see [Create Temporary Upload Location In Group](/rest/api/power-bi/imports/create-temporary-upload-location-in-group) and the [Import Large Files](https://github.com/microsoft/PowerBI-Developer-Samples/blob/master/PowerShell%20Scripts/Import%20Large%20Files) PowerShell script. This is only supported for Premium capacity workspaces.
        /// - To create a dataflow from a model.json file, set `datasetDisplayName` to *model.json*, as described in [URI parameters](/rest/api/power-bi/imports/post-import-in-group#uri-parameters).
        ///
        /// ## Permissions
        ///
        /// This API call can be called by a service principal profile. For more information see: [Service principal profiles in Power BI Embedded](/power-bi/developer/embedded/embed-multi-tenancy).
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All
        ///
        /// ## Limitations
        ///
        /// - Dataflows with service principal aren't supported.
        /// - Importing a Power BI .pbix file from OneDrive isn't supported.
        /// - Importing a file that has a **protected** sensitivity label isn't supported for service principals.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public Response<Import> PostImportInGroup(Guid groupId, string datasetDisplayName, ImportInfo importInfo, ImportConflictHandlerMode? nameConflict = null, bool? skipReport = null, bool? overrideReportLabel = null, bool? overrideModelLabel = null, Guid? subfolderObjectId = null, CancellationToken cancellationToken = default)
        {
            if (datasetDisplayName == null)
            {
                throw new ArgumentNullException(nameof(datasetDisplayName));
            }
            if (importInfo == null)
            {
                throw new ArgumentNullException(nameof(importInfo));
            }

            using var message = CreatePostImportInGroupRequest(groupId, datasetDisplayName, importInfo, nameConflict, skipReport, overrideReportLabel, overrideModelLabel, subfolderObjectId);
            _pipeline.Send(message, cancellationToken);
            switch (message.Response.Status)
            {
                case 200:
                case 202:
                    {
                        Import value = default;
                        using var document = JsonDocument.Parse(message.Response.ContentStream);
                        value = Import.DeserializeImport(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        internal HttpMessage CreateGetImportInGroupRequest(Guid groupId, Guid importId)
        {
            var message = _pipeline.CreateMessage();
            var request = message.Request;
            request.Method = RequestMethod.Get;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/v1.0/myorg/groups/", false);
            uri.AppendPath(groupId, true);
            uri.AppendPath("/imports/", false);
            uri.AppendPath(importId, true);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            return message;
        }

        /// <summary> Returns the specified import from the specified workspace. </summary>
        /// <param name="groupId"> The workspace ID. </param>
        /// <param name="importId"> The import ID. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// ## Permissions
        ///
        /// This API call can be called by a service principal profile. For more information see: [Service principal profiles in Power BI Embedded](/power-bi/developer/embedded/embed-multi-tenancy).
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All or Dataset.Read.All
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public async Task<Response<Import>> GetImportInGroupAsync(Guid groupId, Guid importId, CancellationToken cancellationToken = default)
        {
            using var message = CreateGetImportInGroupRequest(groupId, importId);
            await _pipeline.SendAsync(message, cancellationToken).ConfigureAwait(false);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        Import value = default;
                        using var document = await JsonDocument.ParseAsync(message.Response.ContentStream, default, cancellationToken).ConfigureAwait(false);
                        value = Import.DeserializeImport(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        /// <summary> Returns the specified import from the specified workspace. </summary>
        /// <param name="groupId"> The workspace ID. </param>
        /// <param name="importId"> The import ID. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// ## Permissions
        ///
        /// This API call can be called by a service principal profile. For more information see: [Service principal profiles in Power BI Embedded](/power-bi/developer/embedded/embed-multi-tenancy).
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All or Dataset.Read.All
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public Response<Import> GetImportInGroup(Guid groupId, Guid importId, CancellationToken cancellationToken = default)
        {
            using var message = CreateGetImportInGroupRequest(groupId, importId);
            _pipeline.Send(message, cancellationToken);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        Import value = default;
                        using var document = JsonDocument.Parse(message.Response.ContentStream);
                        value = Import.DeserializeImport(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        internal HttpMessage CreateCreateTemporaryUploadLocationInGroupRequest(Guid groupId)
        {
            var message = _pipeline.CreateMessage();
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/v1.0/myorg/groups/", false);
            uri.AppendPath(groupId, true);
            uri.AppendPath("/imports/createTemporaryUploadLocation", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            return message;
        }

        /// <summary> Creates a temporary blob storage upload location for importing large Power BI .pbix files that are between 1 GB and 10 GB in size. </summary>
        /// <param name="groupId"> The workspace ID. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// To import large Power BI .pbix files:
        ///
        /// 1. Create a temporary upload location using this API call.
        /// 1. Upload the Power BI .pbix files using the *shared access signature* URL from the API call response.
        /// 1. Call [Post Import In Group](/rest/api/power-bi/imports/post-import-in-group), specifying the *shared access signature* URL in the `fileUrl` parameter of the [request body](/rest/api/power-bi/imports/post-import-in-group#request-body).
        ///
        /// ## Permissions
        ///
        /// This API call can be called by a service principal profile. For more information see: [Service principal profiles in Power BI Embedded](/power-bi/developer/embedded/embed-multi-tenancy).
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All
        ///
        /// ## Limitations
        ///
        /// Importing large Power BI .pbix files between 1 GB and 10 GB in size is only available for Premium capacity workspaces.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public async Task<Response<TemporaryUploadLocation>> CreateTemporaryUploadLocationInGroupAsync(Guid groupId, CancellationToken cancellationToken = default)
        {
            using var message = CreateCreateTemporaryUploadLocationInGroupRequest(groupId);
            await _pipeline.SendAsync(message, cancellationToken).ConfigureAwait(false);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        TemporaryUploadLocation value = default;
                        using var document = await JsonDocument.ParseAsync(message.Response.ContentStream, default, cancellationToken).ConfigureAwait(false);
                        value = TemporaryUploadLocation.DeserializeTemporaryUploadLocation(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        /// <summary> Creates a temporary blob storage upload location for importing large Power BI .pbix files that are between 1 GB and 10 GB in size. </summary>
        /// <param name="groupId"> The workspace ID. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// To import large Power BI .pbix files:
        ///
        /// 1. Create a temporary upload location using this API call.
        /// 1. Upload the Power BI .pbix files using the *shared access signature* URL from the API call response.
        /// 1. Call [Post Import In Group](/rest/api/power-bi/imports/post-import-in-group), specifying the *shared access signature* URL in the `fileUrl` parameter of the [request body](/rest/api/power-bi/imports/post-import-in-group#request-body).
        ///
        /// ## Permissions
        ///
        /// This API call can be called by a service principal profile. For more information see: [Service principal profiles in Power BI Embedded](/power-bi/developer/embedded/embed-multi-tenancy).
        ///
        /// ## Required Scope
        ///
        /// Dataset.ReadWrite.All
        ///
        /// ## Limitations
        ///
        /// Importing large Power BI .pbix files between 1 GB and 10 GB in size is only available for Premium capacity workspaces.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public Response<TemporaryUploadLocation> CreateTemporaryUploadLocationInGroup(Guid groupId, CancellationToken cancellationToken = default)
        {
            using var message = CreateCreateTemporaryUploadLocationInGroupRequest(groupId);
            _pipeline.Send(message, cancellationToken);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        TemporaryUploadLocation value = default;
                        using var document = JsonDocument.Parse(message.Response.ContentStream);
                        value = TemporaryUploadLocation.DeserializeTemporaryUploadLocation(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        internal HttpMessage CreateGetImportsAsAdminRequest(string expand, string filter, int? top, int? skip)
        {
            var message = _pipeline.CreateMessage();
            var request = message.Request;
            request.Method = RequestMethod.Get;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/v1.0/myorg/admin/imports", false);
            if (expand != null)
            {
                uri.AppendQuery("$expand", expand, true);
            }
            if (filter != null)
            {
                uri.AppendQuery("$filter", filter, true);
            }
            if (top != null)
            {
                uri.AppendQuery("$top", top.Value, true);
            }
            if (skip != null)
            {
                uri.AppendQuery("$skip", skip.Value, true);
            }
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            return message;
        }

        /// <summary> Returns a list of imports for the organization. </summary>
        /// <param name="expand"> Expands related entities inline. </param>
        /// <param name="filter"> Returns a subset of a results based on [Odata](https://docs.oasis-open.org/odata/odata/v4.01/odata-v4.01-part2-url-conventions.html#sec_SystemQueryOptions) filter query parameter condition. </param>
        /// <param name="top"> Returns only the first n results. </param>
        /// <param name="skip"> Skips the first n results. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// ## Permissions
        ///
        /// - The user must be a Fabric administrator or authenticate using a service principal.
        /// - Delegated permissions are supported.
        ///
        /// When running under service prinicipal authentication, an app **must not** have any admin-consent required premissions for Power BI set on it in the Azure portal.
        ///
        /// ## Required Scope
        ///
        /// Tenant.Read.All or Tenant.ReadWrite.All
        ///
        /// Relevant only when authenticating via a standard delegated admin access token. Must not be present when authentication via a service principal is used.
        ///
        /// ## Limitations
        ///
        /// Maximum 200 requests per hour.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public async Task<Response<Imports>> GetImportsAsAdminAsync(string expand = null, string filter = null, int? top = null, int? skip = null, CancellationToken cancellationToken = default)
        {
            using var message = CreateGetImportsAsAdminRequest(expand, filter, top, skip);
            await _pipeline.SendAsync(message, cancellationToken).ConfigureAwait(false);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        Imports value = default;
                        using var document = await JsonDocument.ParseAsync(message.Response.ContentStream, default, cancellationToken).ConfigureAwait(false);
                        value = Imports.DeserializeImports(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }

        /// <summary> Returns a list of imports for the organization. </summary>
        /// <param name="expand"> Expands related entities inline. </param>
        /// <param name="filter"> Returns a subset of a results based on [Odata](https://docs.oasis-open.org/odata/odata/v4.01/odata-v4.01-part2-url-conventions.html#sec_SystemQueryOptions) filter query parameter condition. </param>
        /// <param name="top"> Returns only the first n results. </param>
        /// <param name="skip"> Skips the first n results. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <remarks>
        /// ## Permissions
        ///
        /// - The user must be a Fabric administrator or authenticate using a service principal.
        /// - Delegated permissions are supported.
        ///
        /// When running under service prinicipal authentication, an app **must not** have any admin-consent required premissions for Power BI set on it in the Azure portal.
        ///
        /// ## Required Scope
        ///
        /// Tenant.Read.All or Tenant.ReadWrite.All
        ///
        /// Relevant only when authenticating via a standard delegated admin access token. Must not be present when authentication via a service principal is used.
        ///
        /// ## Limitations
        ///
        /// Maximum 200 requests per hour.
        /// &lt;br&gt;&lt;br&gt;
        /// </remarks>
        public Response<Imports> GetImportsAsAdmin(string expand = null, string filter = null, int? top = null, int? skip = null, CancellationToken cancellationToken = default)
        {
            using var message = CreateGetImportsAsAdminRequest(expand, filter, top, skip);
            _pipeline.Send(message, cancellationToken);
            switch (message.Response.Status)
            {
                case 200:
                    {
                        Imports value = default;
                        using var document = JsonDocument.Parse(message.Response.ContentStream);
                        value = Imports.DeserializeImports(document.RootElement);
                        return Response.FromValue(value, message.Response);
                    }
                default:
                    throw new RequestFailedException(message.Response);
            }
        }
    }
}
